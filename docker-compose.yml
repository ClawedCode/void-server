# Docker Compose - Infrastructure Services
# Usage: docker compose up -d
#
# Runs infrastructure services in Docker while void-server runs natively with PM2.
# This enables direct browser launching for authentication (Docker can't open desktop windows).

services:
  # ==========================================================================
  # Neo4j - Graph Database for Memory System
  # ==========================================================================
  neo4j:
    image: neo4j:5-community
    container_name: void-neo4j
    restart: unless-stopped
    ports:
      - "7474:7474"   # Browser UI
      - "7687:7687"   # Bolt protocol
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-voidserver}
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=1G
      - NEO4J_dbms_memory_pagecache_size=512m
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # ==========================================================================
  # IPFS Kubo - Decentralized Storage
  # ==========================================================================
  ipfs:
    image: ipfs/kubo:latest
    container_name: void-ipfs
    restart: unless-stopped
    ports:
      - "5001:5001"   # API
      - "8080:8080"   # Gateway
    environment:
      - IPFS_PROFILE=server
      - IPFS_TELEMETRY=off
    volumes:
      - ipfs_data:/data/ipfs
    healthcheck:
      test: ["CMD-SHELL", "ipfs id || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ==========================================================================
  # Ollama - Local AI Inference Engine
  # ==========================================================================
  ollama:
    image: ollama/ollama:latest
    container_name: void-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ./data/models:/root/.ollama
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

volumes:
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  ipfs_data:
    driver: local
